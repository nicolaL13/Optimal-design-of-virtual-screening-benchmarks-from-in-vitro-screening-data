{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5deb497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2084bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV files\n",
    "df1 = pd.read_csv('screening.csv')#screening assay data\n",
    "df2 = pd.read_csv('confirmatory.csv')#confirmatory assay data \n",
    "\n",
    "# Concatenate both DataFrames and save to csv \n",
    "combined_df = pd.concat([df1, df2])\n",
    "combined_df.to_csv('combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3277595",
   "metadata": {},
   "source": [
    "# cleaning data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33ddaf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if each 'Potential Target' list is valid\n",
    "def is_valid_target_list(target_list_str):\n",
    "    \"\"\"\n",
    "    validate whether the input string represents a list of lists of strings \n",
    "    \n",
    "    target_list_str: string of a list  \n",
    "    \n",
    "    return: list of boolean values \n",
    "    \"\"\"\n",
    "    try:\n",
    "        target_list = ast.literal_eval(target_list_str)  # Try to evaluate the input string as a Python literal using ast.literal_eval converting the string representation of a list into an actual list.\n",
    "        if not isinstance(target_list, list):  # Check if the result of the evaluation is a list.\n",
    "            return False  # If it's not a list, return False.\n",
    "    except (ValueError, SyntaxError):  # If there's a ValueError or SyntaxError while trying to evaluate the string,return False. These errors might occur if the string is not a valid Python literal.\n",
    "        return False\n",
    "    return True  # If everything went well, return True. This means the input string represents a valid list of lists.\n",
    "\n",
    "def transform_string(s):\n",
    "    \"\"\"\n",
    "    Function to transform a string to uppercase and remove spaces and/or brackets \n",
    "    s: string to be transformed \n",
    "    return: transformed string \n",
    "    \"\"\"\n",
    "    \n",
    "    return s.upper().replace(\" \", \"\").replace('[','').replace(']','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc8b5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_target_rows = combined_df[combined_df['Potential Target'].apply(is_valid_target_list)] #find the rows of screening and confimratory data that have errors in the poteintial target list \n",
    "\n",
    "# Save the invalid target rows to a new CSV file to be able to manually fix \n",
    "invalid_target_rows.to_csv('invalid_target_rows.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05272387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after fixing previus invalid rows, each string can be cleaned \n",
    "\n",
    "with open('combined.csv', newline='') as csvfile: \n",
    "    reader = csv.DictReader(csvfile) # Create a CSV reader object for the opened file.\n",
    "    data = [row for row in reader]   # Read the CSV data and store it as a list of dictionaries.\n",
    "\n",
    "for row in data: # Iterate through each row in the data read from the CSV.\n",
    "    new_row=[] # Create an empty list to store transformed values.\n",
    "    target_list=list(row['Potential Target'].split(','))# create a list of each comma separated string in the potential Target list.\n",
    "    for string in target_list:\n",
    "        string= transform_string(string)# Apply the 'transform_string' function to each string.\n",
    "        new_row.append(string)# Add the transformed string to the new list\n",
    "    row['Potential Target']=new_row # Replace the original 'Potential Target' list with the transformed list of strings.\n",
    "\n",
    "with open('edited_target_data.csv', 'w', newline='') as csvfile: #create new csv file for transformed data including other columns that have not been changed\n",
    "    fieldnames = ['AID', 'Potential Target', 'source_name','type']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c53d11",
   "metadata": {},
   "source": [
    "# Grouping Assays based on Target Names and Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "32b5568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_common_strings(string1, string2):\n",
    "    \"\"\"function to find common strings between two lists of strings\n",
    "    string 1: list of strings that is being compared \n",
    "    string2: list of strings that is being compared\n",
    "    \n",
    "    return: a list of common strings from both lists \n",
    "    \"\"\"\n",
    "    return list(set(string1) & set(string2))\n",
    "\n",
    "# Group data based on column 3 (Age) values\n",
    "grouped_data = {} #empty dictionary \n",
    "for row in data: #iterate through data of assays \n",
    "    source = row['source_name'] #find the source name\n",
    "    if source not in grouped_data: #check to see if already in new dictionary, if not create a new key value pair with key:source value:row of data \n",
    "        grouped_data[source] = [] \n",
    "    grouped_data[source].append(row)\n",
    "\n",
    "    \n",
    "result_data = [] #empty list for grouped data to go \n",
    "for source, rows in grouped_data.items(): #iterate through dictionary\n",
    "    for i, row1 in enumerate(rows): \n",
    "        for j, row2 in enumerate(rows[i + 1:], start=i + 1): #iterate through each value in dictionary to get pairs of rows to compare against\n",
    "            common_names = find_common_strings(row1['Potential Target'].split(','), row2['Potential Target'].split(',')) # separate the potential target column values by commas and find the common target names.\n",
    "            if len(common_names) >= 1: #if there is common strings found, the rows that include the shared strings are added to new list of data\n",
    "                result_data.append(row1) \n",
    "                result_data.append(row2)\n",
    "    \n",
    "# Remove duplicate records from the result_data list\n",
    "unique_result_data = [] #list for data that has no duplicates \n",
    "seen_ids = [] #list of aids that are in the data\n",
    "for row in result_data:\n",
    "    row_id = row['AID'] \n",
    "    if row_id not in seen_ids: #if aid has not already been added to list, add row of data to list and add aid to list\n",
    "        unique_result_data.append(row)\n",
    "        seen_ids.append(row_id)\n",
    "\n",
    "#write new grouped and cleaned data to new csv file \n",
    "with open('final_grouped_data_edited.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['AID', 'Potential Target', 'source_name','type']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(unique_result_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1022c496",
   "metadata": {},
   "source": [
    "# find data that was removed at this stage of filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aca30164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the IDs in the original data that are not in the final unique result data\n",
    "all_ids = {row['AID'] for row in data}\n",
    "final_result_ids = {row['AID'] for row in unique_result_data}\n",
    "not_in_final_result_ids = all_ids - final_result_ids\n",
    "\n",
    "# Filter out the rows not in the final unique result data by using the lists of aids created above\n",
    "not_in_final_result_data = [row for row in data if row['AID'] in not_in_final_result_ids]\n",
    "\n",
    "# Write the data with IDs not in the final result to a new CSV file\n",
    "with open('not_in_final_result_data2.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['AID', 'Potential Target', 'source_name','type']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(not_in_final_result_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bioassays]",
   "language": "python",
   "name": "conda-env-bioassays-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
